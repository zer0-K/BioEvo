
// This document will be improved to document the whole project


X) JMP01 function execution architecture


As you will see in the section 'Teleonomical design', the algorithm designs are function-orientied, i.e. we want the concept of 
function to be the core of the code of an algorithm. 
We proceed as follows :
A function has an ID, and we want to be able to call a function by providing its ID.
The algo also has a stack, on which we can provide the arguments of the function and the returned value of the function.

The name of this arch is JMP01 because the meta-execution function (the function for which the purpose is to execute the function
with the given ID) is located at the position 1 in the molecular body. For example, if the second gene value is 34, then the meta-execution 
function begins at position 34*7 (program pointer at line 34).
To execute a function, we just need to jump to the line specified at gene 01.

Moreover, in this architecture the first instruction to be executed is a jump to the main function, this also contributes to naming 
this architecture "JMP01".


X) Free molecules and algorithms

In the EvoAlgo/X86Algo's project, there are two types of entities :

    - algorithms, that can be executed. They have an input, a code (and molecular body) and an output 

    - free molecules, that cannot be executed per se. They corresponds to buoyant entities encoding info that algos can eat




X) Teleonomical design (macro)


Like in evolutionary biology, to understand the history of a species (for example), a good tool we have 
(one of the best in biology, but here we have way more because we have full control on the envirionment, the individuals, and time) is 
is the connection between a design and a function : knowing a design, we can "guess" (know with a certain confidence) the purpose of 
the structure and the evolutionary pressures the ancestor species has faced in the past, and knowing the past selective pressures we can have 
a better understanding of the working of the current species.
Natural evolution is actually blind, it does not know in advance the problem that a species/subspecies/individual/organ/gene should solve 
in order to survive, but it is actually really good at solving it. This evolutionary concept is called "teleonomy" : it is as if 
living beings have a purpose. 

We suppose that adaptative algorithms work in a similar way as adaptative biological structures, especially for this design-function connection. 
(actually we do not suppose, we (I !) want artificial work like this here, we want to study artifical structures with the same behavior !)
We will translate this hypothesis in artificial life as follows :
        The design of an algorithm is teleonomical
        i.e. the modules/organs of an algorithm will have an ID that corresponds to the problem they solve

--> like living beings, artificial beings do not have a purpose per se, they have adapted : it is as if they have a purpose, hence the 
concept of teleonomy (and not the concept of will)


We can ensure the correctness of this choice of design (i.e. an ID for each problem) by considering Gödel's arithmetisation :
in a formal system (with some minimal requirements), we can map each proposition of the system to a natural number (Gödel's numbering for ex).
For this project, we will translate the teleonomical design thanks to this arithmetisation :
we will say an algorithm's goal is the decision problem it satisfies.
For example :
    - if the goal is to add 2 numbers, it means the algo's output must satisfy the decision problem "x+y=z is true" for x,y the inputs and z the output
    - if we want to sort a list, the goal of the algo is the decision problem "$a_1\leq a_2\leq\dots\leq a_n$ ?" for $(a_i)_{1\leq i\leq n}$ a list of integers
        
It corresponds to general problem :
$\forall x \in E, \tilde{f}(x)=f(x)$ where f is the goal (target function) and $\tilde{f}$ is the approximated function ; it is the algorithm.

Since any decision problem can be mapped to a natural number, we can define what we will call a teleonomical number.
The teleonomical number is the ID corresponding to the decision problem an algorithm solves/defines.

For the moment teleonomical IDs will be created by the experimenter. Later, I'll probably work on teleonomical ID generation by algorithms 
(we may need to generate a formal language in EvoX ASM so that we can map a problem (expressed in that language) to an integer (Gödel's arithmetisation)).


It means the evolutionary processes will be split into two parts:
    - goal definers : algorithms that will create relevant decision problems 
    - goal solvers : algorithms that will solve these decision problems


For that purpose, we will add some meta data at the beginning of the algos and the free molecules.
    - for algos:
        - meta-teleonomical field :
            - if 0, the algo should define goals/decision problems
            - if 1, the algo should solve problems
        - teleonomical field : the list of all the problems the algo defines or solves (i) (ii)
    - for free molecules :
        - type field :
            - if 0 : corresponds to training data
            - if 1 : corresponds to test data
            - if 2 : corresponds to replication data
            - if 3 : an algo can integrate it as new func in molecular body
            - if 4 : requesting for an algo to output a func solving/defining a goal
        - meta-teleonomical field:
            - if 0 : the data corresponds to a problem definition
            - if 1 : the data corresponds to a problem solving
        - teleonomical field : teleonomical ID of the data
        - other meta data depending on the type of the free molecules


Note : we can now see how "viruses" (entities with wrong teleonomical ID) can break all this logic. We will focus on them later.

(i) --> an algo contains the list of the problems it tackles : this is, in a way, the functional evolutionary description of the algorithm
        We will use this list of IDs for evolutionary analyses, and we redefine the following words :
            - species : all algorithms that solve/define the same problems
            - subspecies : within a species, there might be some clusters of significatively different individuals (molecular_body clustering) ;
                each identifiable cluster is a "subspecies", and outliers are "explorat" 
                Since the number of cluster depends on the method used (KNN, SVM,...), we need to keep in mind that the notion of 
                subspecies is conventional (but not arbitrary) (note that a subspecies can be divised into several clusters, and so on)
            - taxon : list of problems (if a species solves problems with ID $10, 11, 12, 13$, then $12, 13$ is a taxon)
                A taxon can define a species (the algorithms that solve/define these problems and no more), but different species can share the same taxon
            - phylogenetics : history of the emergence of taxons

(ii) --> taking into account what has been said above in (i), the teleonomical field can be split into two parts:
        - the list of problems the algorithm can actually solve
        - the list of problems that the ancestors of the algorithm faced during the evolution



X) Genericity and specificity

Another theoretical hypothesis in the theory of Evolution that is sometimes/often stated is the folowing :
    elementary generalist systems are rare, the majority of the time they correspond to an organized agglomeration of specialized subsystems

In evolutionary psychology, it corresponds to :
    generalist (cognitive) modules are subdivised into several specialized (cognitive) submodules.

Since this project belongs to evolutionary psychology in a way, we will also take this hypothesis.
Indeed, like in evolutionary psychology we are interested in the creation of algorithms in the context of natural selection.
The two main differences with evolutionary psychology are :
    - selection is artificial
    - the information carrier is different (cells in biology, bits in computer science)

However, the theoretical tools and metodology are the same : we want the artificial selection to behave like natural selection 
(i.e. survival of the fittest), and we want to view individuals as information processing systems 
(in biology, it corresponds to the computationalism theory of the mind).


This will imply that we need to stagger the system into different teleonomical steps : a generalist program will gather several specialized subprograms.


(we may add that, maybe, the tendency to specialization is, up to a certain level of abstraction, a special case of teleonomical design. 
Maybe specialization is a teleonomical design. But specialization is such an important concept that we will consider it as another one)



X) Teleonomical design (micro)

The two hypotheses above (teleonomical design and tendency to specialization) are the cornerstones of our engineering, so much as we would 
translate them into genetical properties locally :
    THE MOLECULAR BODY CAN BE SPLIT INTO A LOT OF SUBPARTS FUNCTIONNALY SPECIALIZED


There are three important remarks :
    - the two hypotheses do not describe the degree of causality : some genes may have a proximal utility, while others may have a distal 
        (ultimate) utility. For example redundancy of the molecular body can be mistakenly seen as not teleonomical nor specialized (in term of
        improving chances of survival), but it is because it garantees robustness against mutation (which is a proxy for fitness)
    - these assumptions are not strongly universal : they are the "H_0 hypothesis", not everything is subject to it, some things can 
        be useless and we don't want to ignore them (such as spandrels, genetic drift). However, the hypotheses suggest that a "useless" trait 
        will tend to become useful at some point later in the evolution. We will focus on them because these traits can actually be an adaptation 
        for functional exploration : allowing the apparition of new 'useless' traits may increase the chance that one of these traits 
        solves a problem that was unsolved yet, or may unlock a new behavior/function improving fitness/survival.


The specialization hypothesis, as it has been described in the corresponding section, also means that a subpart of the molecular body can be part 
of bigger specialized part of the molecular body, and can also be split into specialized subparts.


Programmatically, we will translate everything as follows :
The molecular body is a list of integers, split into different parts P1, P2,..., Pn. Since we are working with integers, there are some 
parts that are fundamental, i.e. such that they cannot be split into smaller specialized parts. These parts are called instructions coding, 
and in this project they correspond to a group of 7 nucleotides.
All the other parts of the code (P1,...,Pn) will use these fundamental rocks.



X) Autopoiesis/autonomical (morpho)genesis

In philosophy of Evolution, the capacity of an entity to generate itself by itself is called autopoiesis, or autonomical morphogenesis.
To compare with biology, the molecular body is the set of integers, and the phenotype is the set of instructions. 
An instruction for our algos corresponds to a phenotypical trait of a biological organism, the bedrock for playing with adaptations.

Talking of self-generation of an algorithm, we want :
- self-genesis : the genesis comes from the molecular body of the individual
- morphogenesis : the genesis creates the code of the algo (its instructions)

Evolution is blind but patient, however we don't have much time but we are not as blind as Evolution, so we allow ourselves to cheat a bit by 
providing the algo an ad hoc structure : we won't evolve autopoiesis from ground zero, the experimenter actually provides a code that he has 
created, allowing the algo to self-generate already, and with evolution the algo will later be able to mutate and change its genesis process.



X) Elementary functions / amino acids

An elementary function, that we will call "amino acid".